/* 
 * (C) 2003 Clemson University and The University of Chicago 
 *
 * See COPYING in top-level directory.
 */

/** \file
 *  \ingroup mgmtint
 *
 *  PVFS2 management interface routines for obtaining server performance
 *  statistics.  This is used primarily for monitoring purposes.
 */

#include <string.h>
#include <assert.h>

#include "pvfs2-server.h"
#include "server-config.h"
#include "pvfs2-debug.h"
#include "job.h"
#include "gossip.h"
#include "str-utils.h"
#include "pvfs2-mgmt.h"
#include "pint-cached-config.h"
#include "PINT-reqproto-encode.h"
#include "pint-perf-counter.h"
#include "pint-util.h"


#define HISTORY_MAX 2
#define HISTORY 2		/* Just the most current load */

struct PVFS_mgmt_perf_stat ** perf_load_matrix = NULL;
PVFS_BMI_addr_t * perf_load_addr_array = NULL;    

int io_server_count = 0;
int perf_load_initialized = 0;

static int perf_mon_client_comp_fn(
	void* v_p, struct PVFS_server_resp *resp_p, int i);

PVFS_error PVFS_get_io_server_array(
	PVFS_fs_id fs_id,
	int server_type,
	PVFS_BMI_addr_t *addr_array,
	int *inout_count_p);

PVFS_error PVFS_count_io_servers(
	PVFS_fs_id fs_id,
	int server_type,
	int *count);


%%

nested machine pvfs2_perf_mon_client_sm
{
	state perf_mon_client_init
	{
		run per_mon_client_init;
		success => setup_msgpair;
        default => cleanup;
	}

	state setup_msgpair
	{
		run perf_mon_client_setup_msgpair;
		success => xfer_msgpair;
        default => cleanup;
	}

	state xfer_msgpair
	{
		jump pvfs2_msgpairarray_sm;
        default => cleanup;
	}

	state cleanup
	{
		run perf_mon_client_cleanup;
        default => return;
	}
}

%%

static PINT_sm_action per_mon_client_init(
	struct PINT_smcb *smcb, job_status_s *js_p){
	struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);    

	int ret,i;
	int* count = NULL;
	PVFS_fs_id coll_id = PINT_config_get_fs_id_by_fs_name(get_server_config_struct(),"pvfs2-fs");
	int32_t flags = PINT_SERVER_TYPE_IO;
	char *alias;
	int is_ios = 0;

	alias = PINT_util_guess_alias();
	s_op->target_fs_id = coll_id;

	//gossip_debug(GOSSIP_LB_DBUGBUG,"per_mon_client_init->:coll_id: %d***\n",(int)coll_id);

	js_p->error_code = 0;

	count = &(io_server_count); /* & ? */

	/* To allocate the load array */
	if(perf_load_initialized == 0){
		/* Fix me: when meta server and io server are same */

		/* local server is i/o */
		is_ios = PINT_is_io_server(get_server_config_struct(),coll_id,alias);

		/* count I/O servers  */
		ret = PVFS_count_io_servers(coll_id, flags, count);
//		gossip_debug(GOSSIP_LB_DEBUG, "IO server count is %d\n",*count);
		
		/* substract myself */
		if(is_ios)
			io_server_count--;

		
		if(ret < 0)
		{
			PVFS_perror("PVFS_mgmt_count_servers", ret);
			return(ret);
		}
		gossip_debug(GOSSIP_LB_DEBUG, "per_mon_client_init->server count: %d\n",io_server_count);

		/* allocate a 2 dimensional array for statistics */
		perf_load_matrix = (struct PVFS_mgmt_perf_stat**)malloc(
			io_server_count*sizeof(struct PVFS_mgmt_perf_stat *));
		if(!perf_load_matrix)
		{
			PVFS_perror("malloc", -1);
			return(-1);
		}

		
		for(i = 0; i < io_server_count; i++)
		{
			perf_load_matrix[i] = (struct PVFS_mgmt_perf_stat *)
				malloc(HISTORY * sizeof(struct PVFS_mgmt_perf_stat));
			if (perf_load_matrix[i] == NULL)
			{
				PVFS_perror("malloc", -1);
				return -1;
			}
		}
		
		/*
		 * Fix me: del myself
		 */
		/* build a list of servers to talk to */
		perf_load_addr_array = (PVFS_BMI_addr_t *)
			malloc(io_server_count * sizeof(PVFS_BMI_addr_t));
		if (perf_load_addr_array == NULL)
		{
			PVFS_perror("malloc", -1);
			return -1;
		}

		ret = PVFS_get_io_server_array(
			coll_id ,
			flags,
			perf_load_addr_array,
			count);
		if (ret < 0)
		{
			PVFS_perror("PVFS_mgmt_get_server_array", ret);
			return -1;
		} 
		for (i = 0; i < *count; i++){
			gossip_debug(GOSSIP_LB_DEBUG, "BMI load array[%d] = %lld\n",i, perf_load_addr_array[i]);
		}
//		gossip_debug(GOSSIP_LB_DEBUG, "per_mon_client_init-> count after addr array: %d\n",*count);
		perf_load_initialized = 1;   	
	}
#if 1
	/* allocate an array to keep up with what iteration of statistics
	 * we need from each server 
	 */
	s_op->u.monclient.next_id_array = (uint32_t *) malloc((*count) * sizeof(uint32_t));
	if (s_op->u.monclient.next_id_array == NULL)
	{
		PVFS_perror("malloc", -1);
		return -1;
	}
	memset(s_op->u.monclient.next_id_array, 0, (*count)*sizeof(uint32_t));

	/* allocate an array to keep up with end times from each server */
	s_op->u.monclient.end_time_ms_array = (uint64_t *)
		malloc((*count) * sizeof(uint64_t));
	if (s_op->u.monclient.end_time_ms_array == NULL)
	{
		PVFS_perror("malloc", -1);
		return -1;
	}
#endif
	//printf("server count === %d\n",io_server_count);
	return SM_ACTION_COMPLETE;    
}

static PINT_sm_action perf_mon_client_setup_msgpair(
	struct PINT_smcb *smcb, job_status_s *js_p)
{
	struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
	int i = 0;
	PINT_sm_msgpair_state *msg_p = NULL;
	PVFS_credentials creds;

	/* use client's default value and server job contex */
	s_op->msgarray_op.params.job_timeout = PVFS2_CLIENT_JOB_BMI_TIMEOUT_DEFAULT;
	s_op->msgarray_op.params.retry_limit = PVFS2_CLIENT_RETRY_LIMIT_DEFAULT;
	s_op->msgarray_op.params.retry_delay = PVFS2_CLIENT_RETRY_DELAY_MS_DEFAULT;

	s_op->msgarray_op.params.job_context = server_job_context;
	s_op->msgarray_op.count = io_server_count;

	memset(&creds,0,sizeof(PVFS_credentials));
//	gossip_debug(GOSSIP_LB_DEBUG, "perf_mon_client state: "
	//	     "perf_mon_client_setup_msgpair:%d\n",io_server_count);



	s_op->msgarray_op.msgarray = (PINT_sm_msgpair_state *)malloc(
		s_op->msgarray_op.count  * sizeof(PINT_sm_msgpair_state));

	if (s_op->msgarray_op.msgarray == NULL)
	{
		return -PVFS_ENOMEM;
	}

	foreach_msgpair(&s_op->msgarray_op, msg_p, i)
	{
		PINT_SERVREQ_MGMT_PERF_MON_FILL(
			msg_p->req,
			creds,
			s_op->u.monclient.next_id_array[i],
			HISTORY_MAX,NULL);

		msg_p->fs_id = s_op->target_fs_id;
		msg_p->handle = PVFS_HANDLE_NULL;
		msg_p->retry_flag = PVFS_MSGPAIR_RETRY;
		msg_p->comp_fn = perf_mon_client_comp_fn;
		msg_p->svr_addr = perf_load_addr_array[i];
		gossip_debug(GOSSIP_SERVER_DEBUG,"addr=%lld\n", lld(msg_p->svr_addr));   
	}

	/* immediate return: next state jumps to msgpairarray machine */
	js_p->error_code = 0;
	
	PINT_sm_push_frame(smcb, 0, &s_op->msgarray_op);
	return SM_ACTION_COMPLETE;
}


static PINT_sm_action perf_mon_client_cleanup(
	struct PINT_smcb *smcb, job_status_s *js_p)
{
	struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
	//int errct = 0;
	//PVFS_error error = js_p->error_code;
	if (s_op->msgarray_op.msgarray && (s_op->msgarray_op.msgarray != &s_op->msgarray_op.msgpair))
	{
		free(s_op->msgarray_op.msgarray);
	}

#if 1
	if(s_op->u.monclient.end_time_ms_array)
		free(s_op->u.monclient.end_time_ms_array);
	if(s_op->u.monclient.next_id_array)
		free(s_op->u.monclient.next_id_array);
#endif
	BMI_set_info(s_op->addr, BMI_DEC_ADDR_REF, NULL);

	//return(server_state_machine_complete(smcb));
	return SM_ACTION_COMPLETE;
}

static int perf_mon_client_comp_fn(void* v_p,
				   struct PVFS_server_resp *resp_p,
				   int i)
{
	int j = 0;
	PINT_smcb *smcb = v_p;

	PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_MSGPAIR_PARENT_SM);
	

	/* if this particular request was successful, then store the 
	 * performance information in an array to be returned to caller
	 */
	if (s_op->msgarray_op.msgarray[i].op_status == 0)
	{
		//gossip_debug(GOSSIP_SERVER_DEBUG,"-------------------count:%d,i=%d,%lld,%llu\n",resp_p->u.mgmt_perf_mon.perf_array_count,i,
		//lld(resp_p->u.mgmt_perf_mon.suggested_next_id),llu(resp_p->u.mgmt_perf_mon.end_time_ms));
		//gossip_debug(GOSSIP_SERVER_DEBUG,"----------------read:%d\n",resp_p->u.mgmt_perf_mon.perf_array[0].read);
		if(resp_p->u.mgmt_perf_mon.perf_array!=NULL){
			memcpy(perf_load_matrix[i],
			       resp_p->u.mgmt_perf_mon.perf_array,
			       resp_p->u.mgmt_perf_mon.perf_array_count
			       * sizeof(struct PVFS_mgmt_perf_stat));
		}
		

		//gossip_debug(GOSSIP_LB_DEBUG, "Server addr: %lld, read: %g, write : %X, \n",perf_load_addr_array[i],((double)(perf_load_matrix[i][0].read )/10000.0), + perf_load_matrix[i][0].write);
		
	}
	/* if this is the last response, check all of the status values and 
	 * return error code if any requests failed 
	 */
	if (i == (s_op->msgarray_op.count -1))
	{
		for (j=0; j < s_op->msgarray_op.count; j++)
		{
			if (s_op->msgarray_op.msgarray[j].op_status != 0)
			{
				perf_load_matrix[j] = NULL;
				return(s_op->msgarray_op.msgarray[j].op_status);
			}
		}
	}

	return 0;
}

/** Obtains a list of all servers of a given type in a specific
 *  file system.
 *
 *  \return 0 on success, -PVFS_error on failure.
 */
PVFS_error PVFS_get_io_server_array(
	PVFS_fs_id fs_id,
	int server_type,
	PVFS_BMI_addr_t *addr_array,
	int *inout_count_p)
{
	PVFS_error ret = -PVFS_EINVAL;
	char *alias = PINT_util_guess_alias();
			
	ret = PINT_cached_config_get_io_server_array(
		get_server_config_struct(), fs_id, alias , addr_array, inout_count_p);
	return ret;
}

/** Counts the number of servers of a given type present in a file
 *  system.
 *
 *  \param count pointer to address where output count is stored
 *
 *  \return 0 on success, -PVFS_error on failure.
 */
PVFS_error PVFS_count_io_servers(
	PVFS_fs_id fs_id,
	int server_type,
	int *count)
{
	PVFS_error ret = -PVFS_EINVAL;
	
	ret = PINT_cached_config_count_servers(
		fs_id, server_type, count);
	return ret;
}
/*
 * Local variables:
 *  mode: c
 *  c-indent-level: 4
 *  c-basic-offset: 4
 * End:
 *
 * vim: ft=c ts=8 sts=4 sw=4 expandtab
 */

